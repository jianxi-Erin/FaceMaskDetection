{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c027c45e",
      "metadata": {
        "id": "c027c45e",
        "outputId": "2b5cd351-ba33-4b37-83e2-fc4ee5ac8597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 数据集已存在：/content/dataset\n",
            "✅ 数据集划分完成，训练集数量：682，测试集数量：171\n",
            "📄 已生成配置文件：voc.yaml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# 🧱 配置参数区域\n",
        "# ===============================\n",
        "DATASET_URL = \"andrewmvd/face-mask-detection\"  # kaggle 数据集名称\n",
        "DATASET_DIR = \"dataset\"        # 解压数据集的路径\n",
        "ANNOT_DIR = os.path.join(DATASET_DIR, \"annotations\")\n",
        "IMAGES_DIR = os.path.join(DATASET_DIR, \"images\")\n",
        "\n",
        "OUTPUT_DIR = \"dataset/output\"\n",
        "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(OUTPUT_DIR, \"test\")\n",
        "YAML_PATH = \"voc.yaml\"\n",
        "\n",
        "CLASS_NAMES = [\"with_mask\", \"without_mask\"]\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "# ===============================\n",
        "# 📥 下载并解压数据集\n",
        "# ===============================\n",
        "def download_dataset(dataset_url, output_dir):\n",
        "    try:\n",
        "        import kagglehub\n",
        "    except ImportError:\n",
        "        print(\"❌ 请先安装 kagglehub：pip install kagglehub\")\n",
        "        return\n",
        "\n",
        "    if os.path.exists(output_dir):\n",
        "        print(f\"✅ 数据集已存在：{os.path.abspath(output_dir)}\")\n",
        "        return\n",
        "\n",
        "    print(\"🚀 正在下载数据集中...\")\n",
        "    downloaded_path = kagglehub.dataset_download(dataset_url)\n",
        "    shutil.copytree(downloaded_path, output_dir)\n",
        "    shutil.rmtree(downloaded_path)\n",
        "    print(f\"✅ 数据集下载完成：{os.path.abspath(output_dir)}\")\n",
        "\n",
        "# ===============================\n",
        "# 🔁 VOC → YOLO 格式转换函数\n",
        "# ===============================\n",
        "def convert_voc_to_yolo(xml_file, yolo_save_dir, class_names):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    img_width = int(root.find(\"size/width\").text)\n",
        "    img_height = int(root.find(\"size/height\").text)\n",
        "    label_lines = []\n",
        "\n",
        "    for obj in root.findall(\"object\"):\n",
        "        cls_name = obj.find(\"name\").text\n",
        "        if cls_name not in class_names:\n",
        "            continue\n",
        "        cls_id = class_names.index(cls_name)\n",
        "\n",
        "        bbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bbox.find(\"xmin\").text)\n",
        "        ymin = int(bbox.find(\"ymin\").text)\n",
        "        xmax = int(bbox.find(\"xmax\").text)\n",
        "        ymax = int(bbox.find(\"ymax\").text)\n",
        "\n",
        "        # 转换为归一化中心坐标 + 宽高\n",
        "        x_center = ((xmin + xmax) / 2) / img_width\n",
        "        y_center = ((ymin + ymax) / 2) / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        label_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "    # 保存为 .txt 文件\n",
        "    txt_file = Path(yolo_save_dir) / (Path(xml_file).stem + \".txt\")\n",
        "    with open(txt_file, \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))\n",
        "\n",
        "# ===============================\n",
        "# 🔀 划分数据集并执行转换\n",
        "# ===============================\n",
        "def prepare_dataset(train_ratio):\n",
        "    # 创建输出文件夹\n",
        "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "    os.makedirs(TEST_DIR, exist_ok=True)\n",
        "\n",
        "    # 加载所有标注文件和对应图像\n",
        "    xml_files = sorted(Path(ANNOT_DIR).glob(\"*.xml\"))\n",
        "    img_files = [Path(IMAGES_DIR) / (xml.stem + \".png\") for xml in xml_files]\n",
        "\n",
        "    # 验证文件是否存在\n",
        "    for img in img_files:\n",
        "        if not img.exists():\n",
        "            raise FileNotFoundError(f\"未找到图像文件：{img}\")\n",
        "\n",
        "    # 打乱并划分数据集\n",
        "    data = list(zip(xml_files, img_files))\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * train_ratio)\n",
        "    train_data, test_data = data[:split_idx], data[split_idx:]\n",
        "\n",
        "    def process(data_list, target_dir):\n",
        "        for xml_path, img_path in data_list:\n",
        "            shutil.copy(xml_path, target_dir)\n",
        "            shutil.copy(img_path, target_dir)\n",
        "            convert_voc_to_yolo(xml_path, target_dir, CLASS_NAMES)\n",
        "\n",
        "    process(train_data, TRAIN_DIR)\n",
        "    process(test_data, TEST_DIR)\n",
        "\n",
        "    print(f\"✅ 数据集划分完成，训练集数量：{len(train_data)}，测试集数量：{len(test_data)}\")\n",
        "\n",
        "# ===============================\n",
        "# 📝 生成 YOLO YAML 配置文件\n",
        "# ===============================\n",
        "def create_yaml(path, train_dir, val_dir, class_names):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(f\"train: {os.path.abspath(train_dir)}\\n\")\n",
        "        f.write(f\"val: {os.path.abspath(val_dir)}\\n\\n\")\n",
        "        f.write(f\"nc: {len(class_names)}\\n\")\n",
        "        f.write(f\"names: {class_names}\\n\")\n",
        "    print(f\"📄 已生成配置文件：{path}\")\n",
        "\n",
        "# ===============================\n",
        "# 🚀 主执行入口\n",
        "# ===============================\n",
        "\n",
        "download_dataset(DATASET_URL, DATASET_DIR)\n",
        "prepare_dataset(TRAIN_RATIO)\n",
        "create_yaml(YAML_PATH, TRAIN_DIR, TEST_DIR, CLASS_NAMES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f382b2b",
      "metadata": {
        "id": "0f382b2b",
        "outputId": "0359265c-f4eb-4901-bcff-73c0f4eb1a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.111)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Sat Apr 19 10:09:24 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Ultralytics 8.3.111 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=baseModel/yolov8n.pt, data=voc.yaml, epochs=50, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3285.7±868.6 MB/s, size: 312.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/output/train.cache... 682 images, 17 backgrounds, 0 corrupt: 100%|██████████| 682/682 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1807.3±1425.2 MB/s, size: 340.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/output/test.cache... 171 images, 4 backgrounds, 0 corrupt: 100%|██████████| 171/171 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      10.4G      1.958      3.533      1.534        139        640: 100%|██████████| 22/22 [00:17<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805    0.00279      0.222      0.023    0.00736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      10.7G       1.51      2.252      1.202         44        512: 100%|██████████| 22/22 [00:15<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805    0.00402      0.308      0.107     0.0378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      9.19G       1.38      1.576      1.128         57        864: 100%|██████████| 22/22 [00:15<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805     0.0176      0.709      0.358      0.203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50       9.2G       1.36        1.5        1.1         72        352: 100%|██████████| 22/22 [00:15<00:00,  1.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805       0.97      0.265       0.45      0.281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      11.7G      1.334      1.337      1.104         59        896: 100%|██████████| 22/22 [00:15<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.801      0.431      0.532      0.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      9.31G      1.312      1.317      1.044         80        384: 100%|██████████| 22/22 [00:14<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.677      0.545      0.607      0.379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      8.97G      1.345      1.279      1.035        106        864: 100%|██████████| 22/22 [00:16<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.716      0.581      0.642      0.398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      11.8G      1.272      1.111      1.033        102        672: 100%|██████████| 22/22 [00:15<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.793      0.606      0.686      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      12.5G      1.254      1.111      1.045         64        672: 100%|██████████| 22/22 [00:15<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.789      0.646      0.708      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      11.3G      1.224      1.014      1.028         50        448: 100%|██████████| 22/22 [00:15<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.786       0.65      0.731      0.451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      10.5G      1.206     0.9955       1.02         66        352: 100%|██████████| 22/22 [00:14<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.811      0.666      0.755      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      12.5G      1.214      1.005      1.026         45        384: 100%|██████████| 22/22 [00:14<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.874       0.65      0.758      0.463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      9.97G      1.214     0.9752      1.004         95        800: 100%|██████████| 22/22 [00:13<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.841      0.661      0.767      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      9.15G      1.183      0.939     0.9971         93        576: 100%|██████████| 22/22 [00:15<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.812      0.685      0.779      0.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      13.1G      1.164        0.9      1.016        123        448: 100%|██████████| 22/22 [00:16<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.866       0.69      0.789      0.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      7.62G      1.164      0.868     0.9954         80        544: 100%|██████████| 22/22 [00:15<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.776      0.744      0.789      0.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      8.61G      1.136     0.8459     0.9975         82        736: 100%|██████████| 22/22 [00:14<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.839      0.708      0.793       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      9.33G      1.176     0.8564     0.9828         72        608: 100%|██████████| 22/22 [00:14<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.858      0.697      0.794      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      10.1G      1.155     0.8382     0.9886        134        800: 100%|██████████| 22/22 [00:13<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.814       0.73        0.8      0.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      9.13G      1.162     0.8471      1.001        113        960: 100%|██████████| 22/22 [00:15<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.847      0.723      0.799      0.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      10.7G      1.167     0.8346      1.007         54        704: 100%|██████████| 22/22 [00:15<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.811      0.736      0.808      0.506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50        10G      1.145     0.8074      0.986        120        704: 100%|██████████| 22/22 [00:13<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.829      0.747      0.809      0.515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      10.4G      1.146     0.8413      1.003         61        480: 100%|██████████| 22/22 [00:14<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.811       0.73      0.807      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      11.3G      1.137     0.7848     0.9778         87        800: 100%|██████████| 22/22 [00:14<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.828      0.753      0.819       0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      10.5G      1.137     0.8118      0.984         58        448: 100%|██████████| 22/22 [00:14<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.857      0.737      0.807      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50       9.6G      1.108     0.7783     0.9994         79        704: 100%|██████████| 22/22 [00:14<00:00,  1.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.861       0.73      0.807      0.513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      9.39G      1.133     0.7802     0.9833         43        512: 100%|██████████| 22/22 [00:14<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.864      0.726       0.82      0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      8.92G      1.098     0.7767     0.9767         67        768: 100%|██████████| 22/22 [00:14<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.874      0.732      0.815      0.519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      9.01G      1.164     0.7786      0.968        163        512: 100%|██████████| 22/22 [00:13<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        171        805      0.885       0.73      0.816      0.522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      2.43G      1.125     0.7675     0.9468        185        320:  18%|█▊        | 4/22 [00:01<00:04,  3.70it/s]"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!nvidia-smi\n",
        "from ultralytics import YOLO\n",
        "device = 'cuda'  # 使用GPU训练,可选cuda或cpu\n",
        "\n",
        "model = YOLO(\"baseModel/yolov8n.pt\")  # 使用预训练模型\n",
        "model.train(\n",
        "    data=\"voc.yaml\",\n",
        "    device=0 if device == \"cuda\" else \"cpu\",\n",
        "    epochs=50,\n",
        "    batch=32,\n",
        "    imgsz=640,\n",
        "    optimizer=\"AdamW\",\n",
        "    multi_scale=True,\n",
        "    augment=True,\n",
        "    lr0=0.0001,               # 适当提高初始学习率\n",
        "    lrf=0.01,                # 添加余弦退火最终学习率\n",
        "    amp=True,               # 保持混合精度训练\n",
        "    pretrained=True,        # 确保使用预训练权重\n",
        "    patience=10,               # ⭐️ 添加早停机制 如果10个 epoch 没有提升，自动停止\n",
        "    close_mosaic=10            # 提前关闭 mosaic 增强以稳定收敛\n",
        "    save=True,  # 保存模型\n",
        "    exist_ok=True,\n",
        "    )  # 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预测输出\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------ 全局配置 ------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"runs/detect/train/weights/best.pt\"\n",
        "model = YOLO(MODEL_PATH)\n",
        "INPUT_PATH = \"dataset/output/test/\"  # 输入路径,可以为图片,视频,文件夹,摄像头编号\n",
        "# INPUT_PATH = \"dataset/output/video/test.mp4\"  # 输入路径,可以为图片,视频,文件夹,摄像头编号\n",
        "# INPUT_PATH=0\n",
        "\n",
        "SAVE = True  # 是否保存预测结果\n",
        "OUTPUT_PATH = \"predict/\"  # 预测结果保存路径\n",
        "\n",
        "# ------------ 工具函数 ------------\n",
        "def draw_boxes_pil(image, results):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
        "\n",
        "        text_bbox = font.getbbox(label)\n",
        "        text_w, text_h = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
        "        draw.rectangle([x1, y1 - text_h, x1 + text_w, y1], fill=\"red\")\n",
        "        draw.text((x1, y1 - text_h), label, fill=\"white\", font=font)\n",
        "\n",
        "    return image\n",
        "\n",
        "def save_image(image, save_path, origin_path=None):\n",
        "    if os.path.isdir(save_path):\n",
        "        filename = os.path.basename(origin_path)\n",
        "        save_path = os.path.join(save_path, filename)\n",
        "    else:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    image.save(save_path)\n",
        "    print(f\"✅ 已保存图片: {save_path}\")\n",
        "\n",
        "# ------------ 单图预测 ------------\n",
        "def predict_image(image_path, save=False, save_path=None):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    results = model.predict(image_path, imgsz=640, device=DEVICE)\n",
        "    image = draw_boxes_pil(image, results)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"预测结果\")\n",
        "    plt.show()\n",
        "\n",
        "    if save and save_path:\n",
        "        save_image(image, save_path, origin_path=image_path)\n",
        "\n",
        "# ------------ 视频预测 ------------\n",
        "def predict_video(video_path, save=False, save_path=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"❌ 视频文件无法打开\")\n",
        "        return\n",
        "\n",
        "    if save:\n",
        "        if os.path.isdir(save_path):\n",
        "            filename = os.path.basename(video_path)\n",
        "            save_path = os.path.join(save_path, f\"{os.path.splitext(filename)[0]}.mp4\")\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        fps, w, h = cap.get(5), int(cap.get(3)), int(cap.get(4))\n",
        "        out = cv2.VideoWriter(save_path, fourcc, fps, (w, h))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.predict(frame, imgsz=640, device=DEVICE)\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            cls_id = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"预测中 - 按 Q 退出\", frame)\n",
        "        if save:\n",
        "            out.write(frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    if save:\n",
        "        out.release()\n",
        "        print(f\"✅ 已保存视频: {save_path}\")\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ------------ 文件夹批量图片 ------------\n",
        "def predict_folder(folder_path, save=False, output_dir=None):\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "                img_path = os.path.join(root, file)\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                results = model.predict(img_path, imgsz=640, device=DEVICE)\n",
        "                image = draw_boxes_pil(image, results)\n",
        "\n",
        "                if save and output_dir:\n",
        "                    rel_path = os.path.relpath(img_path, folder_path)\n",
        "                    save_path = os.path.join(output_dir, rel_path)\n",
        "                    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "                    image.save(save_path)\n",
        "\n",
        "    if save:\n",
        "        print(f\"✅ 文件夹预测完成，结果已保存至: {output_dir}\")\n",
        "\n",
        "# ------------ 摄像头实时预测 ------------\n",
        "def predict_camera(index=0):\n",
        "    cap = cv2.VideoCapture(index)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ 无法打开摄像头 {index}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.predict(frame, imgsz=640, device=DEVICE)\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            cls_id = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"摄像头预测 - 按 Q 退出\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ------------ 总入口函数 ------------\n",
        "def run_predict(path, save=False, save_path=None):\n",
        "    if isinstance(path, int):\n",
        "        predict_camera(index=path)\n",
        "    elif os.path.isfile(path):\n",
        "        ext = os.path.splitext(path)[1].lower()\n",
        "        if ext in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]:\n",
        "            predict_image(path, save, save_path)\n",
        "        elif ext in [\".mp4\", \".avi\", \".mov\", \".mkv\"]:\n",
        "            predict_video(path, save, save_path)\n",
        "    elif os.path.isdir(path):\n",
        "        predict_folder(path, save, save_path)\n",
        "    else:\n",
        "        print(\"❌ 无效路径，请确认输入正确的图片/视频/文件夹/摄像头编号\")\n",
        "\n",
        "# ------------ 示例调用 ------------\n",
        "run_predict(INPUT_PATH, SAVE, OUTPUT_PATH)      # 预测输出"
      ],
      "metadata": {
        "id": "HM3Vp9W2iH93"
      },
      "id": "HM3Vp9W2iH93",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}