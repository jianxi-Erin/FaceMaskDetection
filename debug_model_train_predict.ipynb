{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c027c45e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c027c45e",
        "outputId": "b89db8bc-f167-4749-8a63-2f7620fbdc70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… æ•°æ®é›†å·²å­˜åœ¨ï¼š/content/dataset\n",
            "âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼Œè®­ç»ƒé›†æ•°é‡ï¼š682ï¼Œæµ‹è¯•é›†æ•°é‡ï¼š171\n",
            "ðŸ“„ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼švoc.yaml\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# ðŸ§± é…ç½®å‚æ•°åŒºåŸŸ\n",
        "# ===============================\n",
        "DATASET_URL = \"andrewmvd/face-mask-detection\"  # kaggle æ•°æ®é›†åç§°\n",
        "DATASET_DIR = \"dataset\"        # è§£åŽ‹æ•°æ®é›†çš„è·¯å¾„\n",
        "ANNOT_DIR = os.path.join(DATASET_DIR, \"annotations\")\n",
        "IMAGES_DIR = os.path.join(DATASET_DIR, \"images\")\n",
        "\n",
        "OUTPUT_DIR = \"dataset/output\"\n",
        "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(OUTPUT_DIR, \"test\")\n",
        "YAML_PATH = \"voc.yaml\"\n",
        "\n",
        "CLASS_NAMES = [\"with_mask\", \"without_mask\",\"mask_weared_incorrect\"]\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "# ===============================\n",
        "# ðŸ“¥ ä¸‹è½½å¹¶è§£åŽ‹æ•°æ®é›†\n",
        "# ===============================\n",
        "def download_dataset(dataset_url, output_dir):\n",
        "    try:\n",
        "        import kagglehub\n",
        "    except ImportError:\n",
        "        print(\"âŒ è¯·å…ˆå®‰è£… kagglehubï¼špip install kagglehub\")\n",
        "        return\n",
        "\n",
        "    if os.path.exists(output_dir):\n",
        "        print(f\"âœ… æ•°æ®é›†å·²å­˜åœ¨ï¼š{os.path.abspath(output_dir)}\")\n",
        "        return\n",
        "\n",
        "    print(\"ðŸš€ æ­£åœ¨ä¸‹è½½æ•°æ®é›†ä¸­...\")\n",
        "    downloaded_path = kagglehub.dataset_download(dataset_url)\n",
        "    shutil.copytree(downloaded_path, output_dir)\n",
        "    shutil.rmtree(downloaded_path)\n",
        "    print(f\"âœ… æ•°æ®é›†ä¸‹è½½å®Œæˆï¼š{os.path.abspath(output_dir)}\")\n",
        "\n",
        "# ===============================\n",
        "# ðŸ” VOC â†’ YOLO æ ¼å¼è½¬æ¢å‡½æ•°\n",
        "# ===============================\n",
        "def convert_voc_to_yolo(xml_file, yolo_save_dir, class_names):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    img_width = int(root.find(\"size/width\").text)\n",
        "    img_height = int(root.find(\"size/height\").text)\n",
        "    label_lines = []\n",
        "\n",
        "    for obj in root.findall(\"object\"):\n",
        "        cls_name = obj.find(\"name\").text\n",
        "        if cls_name not in class_names:\n",
        "            continue\n",
        "        cls_id = class_names.index(cls_name)\n",
        "\n",
        "        bbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bbox.find(\"xmin\").text)\n",
        "        ymin = int(bbox.find(\"ymin\").text)\n",
        "        xmax = int(bbox.find(\"xmax\").text)\n",
        "        ymax = int(bbox.find(\"ymax\").text)\n",
        "\n",
        "        # è½¬æ¢ä¸ºå½’ä¸€åŒ–ä¸­å¿ƒåæ ‡ + å®½é«˜\n",
        "        x_center = ((xmin + xmax) / 2) / img_width\n",
        "        y_center = ((ymin + ymax) / 2) / img_height\n",
        "        width = (xmax - xmin) / img_width\n",
        "        height = (ymax - ymin) / img_height\n",
        "\n",
        "        label_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "    # ä¿å­˜ä¸º .txt æ–‡ä»¶\n",
        "    txt_file = Path(yolo_save_dir) / (Path(xml_file).stem + \".txt\")\n",
        "    with open(txt_file, \"w\") as f:\n",
        "        f.write(\"\\n\".join(label_lines))\n",
        "\n",
        "# ===============================\n",
        "# ðŸ”€ åˆ’åˆ†æ•°æ®é›†å¹¶æ‰§è¡Œè½¬æ¢\n",
        "# ===============================\n",
        "def prepare_dataset(train_ratio):\n",
        "    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹\n",
        "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
        "    os.makedirs(TEST_DIR, exist_ok=True)\n",
        "\n",
        "    # åŠ è½½æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶å’Œå¯¹åº”å›¾åƒ\n",
        "    xml_files = sorted(Path(ANNOT_DIR).glob(\"*.xml\"))\n",
        "    img_files = [Path(IMAGES_DIR) / (xml.stem + \".png\") for xml in xml_files]\n",
        "\n",
        "    # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "    for img in img_files:\n",
        "        if not img.exists():\n",
        "            raise FileNotFoundError(f\"æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼š{img}\")\n",
        "\n",
        "    # æ‰“ä¹±å¹¶åˆ’åˆ†æ•°æ®é›†\n",
        "    data = list(zip(xml_files, img_files))\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * train_ratio)\n",
        "    train_data, test_data = data[:split_idx], data[split_idx:]\n",
        "\n",
        "    def process(data_list, target_dir):\n",
        "        for xml_path, img_path in data_list:\n",
        "            shutil.copy(xml_path, target_dir)\n",
        "            shutil.copy(img_path, target_dir)\n",
        "            convert_voc_to_yolo(xml_path, target_dir, CLASS_NAMES)\n",
        "\n",
        "    process(train_data, TRAIN_DIR)\n",
        "    process(test_data, TEST_DIR)\n",
        "\n",
        "    print(f\"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼Œè®­ç»ƒé›†æ•°é‡ï¼š{len(train_data)}ï¼Œæµ‹è¯•é›†æ•°é‡ï¼š{len(test_data)}\")\n",
        "\n",
        "# ===============================\n",
        "# ðŸ“ ç”Ÿæˆ YOLO YAML é…ç½®æ–‡ä»¶\n",
        "# ===============================\n",
        "def create_yaml(path, train_dir, val_dir, class_names):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(f\"train: {os.path.abspath(train_dir)}\\n\")\n",
        "        f.write(f\"val: {os.path.abspath(val_dir)}\\n\\n\")\n",
        "        f.write(f\"nc: {len(class_names)}\\n\")\n",
        "        f.write(f\"names: {class_names}\\n\")\n",
        "        f.write(f\"weights: [1.0, 2.0, 4.0]  # æ ¹æ®å„ç±»åˆ«æ ·æœ¬é‡è®¾ç½®é€†æƒé‡\\n\")\n",
        "        f.write(f\"sample_weights: True       # å¯ç”¨åŠ æƒéšæœºé‡‡æ ·\\n\")\n",
        "    print(f\"ðŸ“„ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼š{path}\")\n",
        "\n",
        "# ===============================\n",
        "# ðŸš€ ä¸»æ‰§è¡Œå…¥å£\n",
        "# ===============================\n",
        "\n",
        "download_dataset(DATASET_URL, DATASET_DIR)\n",
        "prepare_dataset(TRAIN_RATIO)\n",
        "create_yaml(YAML_PATH, TRAIN_DIR, TEST_DIR, CLASS_NAMES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f382b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f382b2b",
        "outputId": "b0957c57-3c70-47d5-b572-69f74cf1600d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.119)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Mon Apr 28 03:23:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8             12W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Ultralytics 8.3.119 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=baseModel/yolov8n.pt, data=voc.yaml, epochs=100, time=None, patience=15, batch=32, imgsz=800, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=15, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.3, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.005, momentum=0.937, weight_decay=0.05, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=1.5, cls=3.0, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.3, hsv_s=0.6, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.3, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.2, cutmix=0.0, copy_paste=0.3, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 110MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 307MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3095.3Â±1732.4 MB/s, size: 563.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/output/train... 845 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 845/845 [00:01<00:00, 671.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/output/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2347.7Â±1532.5 MB/s, size: 608.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/output/test... 412 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412/412 [00:01<00:00, 314.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/output/test.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.05), 63 bias(decay=0.0)\n",
            "Image sizes 800 train, 800 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      7.84G     0.3946      19.34      1.669         73        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:32<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834    0.00429      0.197      0.107     0.0438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      7.81G     0.3213      9.896      1.299         81        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:34<00:00,  1.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.232      0.179      0.193      0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      7.62G     0.2967      7.784      1.215         85        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.597      0.385      0.464      0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      9.01G     0.2896      7.172      1.186        120        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.563      0.461       0.49      0.298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      7.85G     0.2746       6.44      1.155        101        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.703        0.5      0.591      0.374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100       7.7G     0.2723      6.118      1.156        116        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.732      0.643      0.705      0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      7.56G     0.2743      6.056      1.156        157        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.835      0.653      0.736      0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      8.21G     0.2694      5.938      1.141        174        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.864      0.679      0.775       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100       6.7G     0.2621      5.566      1.131         86        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.872      0.706      0.781      0.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      8.01G     0.2615      5.467      1.122        119        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:30<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.837      0.684      0.776      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      7.96G      0.258      5.181      1.107        124        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.891      0.735      0.828      0.528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      7.44G     0.2525      5.159      1.106        127        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.907      0.687      0.791      0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      7.41G     0.2507      4.922      1.103         91        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.855      0.741       0.82      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      7.49G     0.2529      4.928      1.094         99        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.856      0.753      0.844      0.557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100       7.6G     0.2519      4.897        1.1        114        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.855      0.803      0.861       0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      8.35G     0.2532      4.932      1.097        194        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.867      0.762      0.825      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      8.91G     0.2543      4.874      1.096        196        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:30<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.894      0.789      0.868       0.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      7.58G     0.2528      4.762      1.083        162        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.887      0.778      0.858      0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      7.71G     0.2468      4.628      1.093        146        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:30<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834       0.92      0.802      0.894       0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      7.61G     0.2482      4.626      1.097        106        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.907      0.828      0.898      0.594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      7.51G     0.2438      4.544      1.089         67        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834       0.89      0.768      0.875      0.571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      7.28G      0.256      4.811      1.093        389        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.847      0.861      0.889      0.583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      7.56G     0.2478      4.594      1.095        137        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.896      0.825       0.89      0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      8.81G     0.2492      4.511       1.08        126        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.882      0.818      0.902      0.612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100       7.4G     0.2471      4.476      1.094        134        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.929       0.84       0.92      0.618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      7.35G     0.2389      4.321      1.078         86        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.854       0.88      0.916      0.601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      8.73G     0.2491      4.387      1.073        133        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.938      0.834      0.913       0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      7.39G     0.2394      4.124      1.069        129        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834       0.93      0.844      0.927      0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      7.21G     0.2448      4.298      1.077        144        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.946      0.844      0.927      0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      7.63G     0.2414      4.205      1.072        105        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.951      0.861      0.939       0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      7.55G     0.2406      4.204      1.077        102        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.949      0.847       0.93      0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      7.79G     0.2434      4.213       1.07        120        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.943       0.86      0.942       0.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      8.43G     0.2423       4.17      1.077        106        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834       0.94      0.872      0.946      0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      8.78G     0.2389      4.174      1.067        134        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.919       0.84      0.915      0.616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      9.04G     0.2388      4.093      1.059        129        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:27<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.937      0.867      0.945      0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      8.32G     0.2424       4.04      1.066        112        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.948      0.879      0.943      0.648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      7.42G     0.2387      4.106       1.07        104        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.947      0.865      0.945      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100       7.7G      0.239      4.024      1.068        100        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:27<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:08<00:00,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.941      0.887      0.948      0.654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      7.89G     0.2371      3.972      1.063         91        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.954      0.873      0.942      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      6.88G     0.2315      3.935      1.062        146        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.949      0.881      0.944      0.645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      6.83G     0.2331      3.923      1.075        123        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:30<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.945      0.867      0.942      0.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      7.24G     0.2341      3.926      1.066        135        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.964      0.893      0.945      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      7.32G     0.2341       3.95      1.058        115        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.934      0.904      0.946      0.646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      7.18G     0.2336      3.912      1.051        121        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:27<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834       0.97      0.882      0.957      0.641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      6.86G     0.2341      3.879      1.067        170        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.951        0.9      0.955      0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      7.42G      0.231      3.828      1.054        104        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:27<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.953      0.858      0.942      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      8.26G     0.2332      3.899      1.058         92        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.972      0.894      0.965      0.668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      7.91G     0.2335      3.945      1.059        199        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.938      0.895      0.947      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      8.12G     0.2305      3.766      1.051        204        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.948      0.911      0.957      0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      9.03G     0.2347      3.828      1.043        252        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.967      0.903      0.951      0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      8.84G     0.2323      3.831      1.059        133        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.941      0.916      0.958      0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      7.69G     0.2327      3.715      1.057        118        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:27<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.974      0.881      0.958      0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      7.17G     0.2342      3.789       1.05        119        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.959        0.9      0.957      0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      8.65G     0.2327      3.766      1.046        108        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.978      0.902      0.966      0.662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      7.06G     0.2302      3.678      1.049         95        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.979      0.877      0.962      0.663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      7.18G     0.2288      3.677      1.041        113        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:29<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.949      0.917      0.964      0.664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      8.09G     0.2338      3.687      1.047        147        800: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:28<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:07<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        412       1834      0.974      0.918      0.961      0.659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      6.41G     0.2341      3.854      1.066        249        800:  30%|â–ˆâ–ˆâ–‰       | 8/27 [00:07<00:22,  1.16s/it]"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!nvidia-smi\n",
        "from ultralytics import YOLO\n",
        "device = 'cuda'  # ä½¿ç”¨GPUè®­ç»ƒ,å¯é€‰cudaæˆ–cpu\n",
        "\n",
        "model = YOLO(\"baseModel/yolov8n.pt\")  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹\n",
        "model.train(\n",
        "    data=\"voc.yaml\",\n",
        "    device=0 if device == \"cuda\" else \"cpu\",\n",
        "    epochs=100,                  # å¢žåŠ æ€»è®­ç»ƒè½®æ¬¡\n",
        "    batch=32,                    # å‡å°batch sizeä»¥é€‚åº”æ›´å¤§åˆ†è¾¨çŽ‡\n",
        "    imgsz=800,                   # ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨ï¼ˆ800->640ï¼‰\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.0005,                    # é™ä½Žåˆå§‹å­¦ä¹ çŽ‡\n",
        "    lrf=0.005,                    # ä½™å¼¦é€€ç«æœ€ç»ˆå­¦ä¹ çŽ‡\n",
        "    warmup_epochs=3,   # æ–°å¢žå­¦ä¹ çŽ‡é¢„çƒ­\n",
        "    weight_decay=0.05,           # æ·»åŠ æƒé‡è¡°å‡é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
        "\n",
        "    # æ•°æ®å¢žå¼ºå¼ºåŒ–\n",
        "    augment=True,\n",
        "    hsv_h=0.3,                   # å¢žå¼ºè‰²è°ƒæ‰°åŠ¨\n",
        "    hsv_s=0.6,                   # å¢žå¼ºé¥±å’Œåº¦æ‰°åŠ¨\n",
        "    translate=0.2,               # å¢žå¤§å¹³ç§»å¹…åº¦\n",
        "    scale=0.5,                   # æ‰©å¤§ç¼©æ”¾èŒƒå›´\n",
        "    shear=0.3,                   # å¢žå¤§å‰ªåˆ‡å¹…åº¦\n",
        "    mosaic=1.0,                  # å…¨ç¨‹å¼€å¯mosaic\n",
        "    close_mosaic=15,             # æœ€åŽ15ä¸ªepochå…³é—­mosaicç¨³å®šè®­ç»ƒ\n",
        "\n",
        "    # æŸå¤±å‡½æ•°è°ƒæ•´\n",
        "    cls=3.0,                     # å¢žå¤§åˆ†ç±»æŸå¤±æƒé‡\n",
        "    box=1.5,                     # å¢žå¤§æ¡†å›žå½’æŸå¤±æƒé‡\n",
        "    dfl=1.5,                     # å¢žå¤§ç‚¹æ¡†æŸå¤±æƒé‡\n",
        "    # fl_gamma=2.0,                # èšç„¦å›°éš¾æ ·æœ¬ï¼ˆç±»ä¼¼focal lossï¼‰\n",
        "\n",
        "    # obj=1.5,                     # é€‚å½“å¢žå¤§ç›®æ ‡å­˜åœ¨æŸå¤±æƒé‡\n",
        "    copy_paste=0.3,              # æ–°å¢žå¤åˆ¶ç²˜è´´å¢žå¼ºï¼ˆç‰¹åˆ«é’ˆå¯¹å°‘æ•°ç±»ï¼‰\n",
        "    mixup=0.2,       # æ–°å¢žMixUpå¢žå¼ºï¼ˆé»˜è®¤æœªå¯ç”¨ï¼‰\n",
        "    # ç±»åˆ«å¹³è¡¡ç­–ç•¥\n",
        "    # éœ€åœ¨data.yamlä¸­æ·»åŠ ï¼š\n",
        "    #   weights: [1.0, 1.0, 2.0, 4.0]  # æŒ‰ç±»åˆ«æ ·æœ¬é‡å€’æ•°è®¾ç½®æƒé‡\n",
        "    #   sample_weights: True           # å¯ç”¨æ ·æœ¬åŠ æƒé‡‡æ ·\n",
        "\n",
        "    # è®­ç»ƒæŽ§åˆ¶\n",
        "    patience=15,                  # å»¶é•¿æ—©åœè§‚å¯ŸæœŸ\n",
        "    dropout=0.3,                 # æ·»åŠ Dropoutæ­£åˆ™åŒ–\n",
        "    amp=True,                    # ä¿æŒæ··åˆç²¾åº¦è®­ç»ƒ\n",
        "    pretrained=True,\n",
        "    save=True,\n",
        "    exist_ok=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HM3Vp9W2iH93",
      "metadata": {
        "id": "HM3Vp9W2iH93",
        "outputId": "5f7a48b9-6112-4a63-8561-4cc98d87b43b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 without_mask, 28.6ms\n",
            "Speed: 34.0ms preprocess, 28.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.6ms\n",
            "Speed: 3.5ms preprocess, 18.6ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.6ms\n",
            "Speed: 1.9ms preprocess, 23.6ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 19.8ms\n",
            "Speed: 1.7ms preprocess, 19.8ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.8ms\n",
            "Speed: 2.7ms preprocess, 18.8ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.6ms\n",
            "Speed: 4.4ms preprocess, 23.6ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.7ms\n",
            "Speed: 3.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.2ms\n",
            "Speed: 4.6ms preprocess, 23.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.4ms\n",
            "Speed: 2.2ms preprocess, 24.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.3ms\n",
            "Speed: 2.0ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 without_masks, 18.5ms\n",
            "Speed: 4.6ms preprocess, 18.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.3ms\n",
            "Speed: 2.3ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.2ms\n",
            "Speed: 4.0ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.9ms\n",
            "Speed: 2.3ms preprocess, 22.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.5ms\n",
            "Speed: 4.0ms preprocess, 22.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.0ms\n",
            "Speed: 4.3ms preprocess, 20.0ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 2.3ms preprocess, 22.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.2ms\n",
            "Speed: 2.7ms preprocess, 25.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 19.4ms\n",
            "Speed: 3.3ms preprocess, 19.4ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.1ms\n",
            "Speed: 2.2ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.6ms\n",
            "Speed: 2.2ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.1ms\n",
            "Speed: 3.8ms preprocess, 23.1ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.2ms\n",
            "Speed: 2.8ms preprocess, 20.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 19.3ms\n",
            "Speed: 5.3ms preprocess, 19.3ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 4.5ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.4ms\n",
            "Speed: 2.0ms preprocess, 24.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.1ms\n",
            "Speed: 3.0ms preprocess, 24.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.0ms\n",
            "Speed: 3.4ms preprocess, 25.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.1ms\n",
            "Speed: 5.3ms preprocess, 25.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 26.0ms\n",
            "Speed: 4.8ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.4ms\n",
            "Speed: 3.5ms preprocess, 22.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.7ms\n",
            "Speed: 2.1ms preprocess, 22.7ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 29.5ms\n",
            "Speed: 4.7ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.3ms\n",
            "Speed: 3.5ms preprocess, 24.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.1ms\n",
            "Speed: 4.2ms preprocess, 22.1ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.0ms\n",
            "Speed: 3.7ms preprocess, 22.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.6ms\n",
            "Speed: 5.1ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.6ms\n",
            "Speed: 5.9ms preprocess, 25.6ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.9ms\n",
            "Speed: 2.1ms preprocess, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.3ms\n",
            "Speed: 2.6ms preprocess, 24.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 28.5ms\n",
            "Speed: 2.4ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.5ms\n",
            "Speed: 4.2ms preprocess, 24.5ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.9ms\n",
            "Speed: 2.6ms preprocess, 20.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.1ms\n",
            "Speed: 4.3ms preprocess, 25.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.0ms\n",
            "Speed: 5.0ms preprocess, 22.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.1ms\n",
            "Speed: 2.1ms preprocess, 24.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.6ms\n",
            "Speed: 2.0ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.2ms\n",
            "Speed: 4.2ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.2ms\n",
            "Speed: 3.6ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 16.5ms\n",
            "Speed: 2.8ms preprocess, 16.5ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.9ms\n",
            "Speed: 3.0ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.8ms\n",
            "Speed: 2.1ms preprocess, 21.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.0ms\n",
            "Speed: 2.5ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.1ms\n",
            "Speed: 2.3ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.1ms\n",
            "Speed: 2.9ms preprocess, 23.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.8ms\n",
            "Speed: 2.5ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.0ms\n",
            "Speed: 2.0ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.3ms\n",
            "Speed: 2.1ms preprocess, 21.3ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.5ms\n",
            "Speed: 3.1ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.3ms\n",
            "Speed: 2.7ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.2ms\n",
            "Speed: 2.2ms preprocess, 17.2ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.1ms\n",
            "Speed: 3.9ms preprocess, 17.1ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 21.1ms\n",
            "Speed: 2.0ms preprocess, 21.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 26.8ms\n",
            "Speed: 2.1ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.8ms\n",
            "Speed: 2.4ms preprocess, 20.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.3ms\n",
            "Speed: 3.7ms preprocess, 20.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 21.6ms\n",
            "Speed: 3.0ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.0ms\n",
            "Speed: 3.0ms preprocess, 22.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 24.4ms\n",
            "Speed: 2.2ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 with_masks, 23.1ms\n",
            "Speed: 2.5ms preprocess, 23.1ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 19.0ms\n",
            "Speed: 3.2ms preprocess, 19.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 20.8ms\n",
            "Speed: 2.8ms preprocess, 20.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.4ms\n",
            "Speed: 4.9ms preprocess, 24.4ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 20.5ms\n",
            "Speed: 5.8ms preprocess, 20.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.8ms\n",
            "Speed: 4.3ms preprocess, 24.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.6ms\n",
            "Speed: 2.5ms preprocess, 18.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.5ms\n",
            "Speed: 3.3ms preprocess, 18.5ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.9ms\n",
            "Speed: 3.3ms preprocess, 21.9ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.6ms\n",
            "Speed: 3.1ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.5ms\n",
            "Speed: 3.2ms preprocess, 19.5ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.5ms\n",
            "Speed: 5.0ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.5ms\n",
            "Speed: 2.8ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 26.4ms\n",
            "Speed: 2.3ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.2ms\n",
            "Speed: 3.1ms preprocess, 22.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.4ms\n",
            "Speed: 3.6ms preprocess, 25.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.8ms\n",
            "Speed: 3.8ms preprocess, 17.8ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.5ms\n",
            "Speed: 3.6ms preprocess, 19.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.4ms\n",
            "Speed: 2.9ms preprocess, 21.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.4ms\n",
            "Speed: 2.8ms preprocess, 20.4ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.1ms\n",
            "Speed: 3.8ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.7ms\n",
            "Speed: 3.1ms preprocess, 17.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.2ms\n",
            "Speed: 2.1ms preprocess, 18.2ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.6ms\n",
            "Speed: 2.5ms preprocess, 17.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.1ms\n",
            "Speed: 4.4ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.8ms\n",
            "Speed: 2.3ms preprocess, 21.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.7ms\n",
            "Speed: 2.7ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.7ms\n",
            "Speed: 2.6ms preprocess, 17.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.2ms\n",
            "Speed: 2.0ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.8ms\n",
            "Speed: 2.1ms preprocess, 20.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.9ms\n",
            "Speed: 2.1ms preprocess, 20.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.9ms\n",
            "Speed: 2.3ms preprocess, 20.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.4ms\n",
            "Speed: 3.9ms preprocess, 20.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.9ms\n",
            "Speed: 4.5ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.6ms\n",
            "Speed: 2.3ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.0ms\n",
            "Speed: 2.3ms preprocess, 21.0ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.6ms\n",
            "Speed: 2.7ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.2ms\n",
            "Speed: 3.5ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 26.9ms\n",
            "Speed: 3.9ms preprocess, 26.9ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.0ms\n",
            "Speed: 2.4ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 2 without_masks, 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 21.5ms\n",
            "Speed: 2.4ms preprocess, 21.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 19.8ms\n",
            "Speed: 4.4ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.4ms\n",
            "Speed: 5.7ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.0ms\n",
            "Speed: 2.7ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.5ms\n",
            "Speed: 1.9ms preprocess, 23.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.1ms\n",
            "Speed: 2.3ms preprocess, 19.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 27.2ms\n",
            "Speed: 3.1ms preprocess, 27.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 20.0ms\n",
            "Speed: 4.2ms preprocess, 20.0ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.8ms\n",
            "Speed: 5.5ms preprocess, 23.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.0ms\n",
            "Speed: 4.1ms preprocess, 22.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.6ms\n",
            "Speed: 3.3ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.5ms\n",
            "Speed: 3.3ms preprocess, 22.5ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.3ms\n",
            "Speed: 3.4ms preprocess, 19.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.8ms\n",
            "Speed: 2.6ms preprocess, 20.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.0ms\n",
            "Speed: 3.3ms preprocess, 21.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.5ms\n",
            "Speed: 4.4ms preprocess, 19.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.0ms\n",
            "Speed: 2.4ms preprocess, 22.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 3.3ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.3ms\n",
            "Speed: 4.5ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 26.2ms\n",
            "Speed: 5.0ms preprocess, 26.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.9ms\n",
            "Speed: 2.3ms preprocess, 19.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 2.6ms preprocess, 21.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.0ms preprocess, 21.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 4.1ms preprocess, 21.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.6ms\n",
            "Speed: 2.9ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.9ms\n",
            "Speed: 2.0ms preprocess, 22.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 2.4ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.6ms\n",
            "Speed: 3.5ms preprocess, 18.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.1ms\n",
            "Speed: 6.1ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.0ms\n",
            "Speed: 4.7ms preprocess, 22.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.7ms\n",
            "Speed: 4.4ms preprocess, 19.7ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.3ms\n",
            "Speed: 2.8ms preprocess, 24.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 2.4ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 4.4ms preprocess, 21.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.6ms\n",
            "Speed: 3.9ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 1.9ms preprocess, 17.6ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.8ms\n",
            "Speed: 2.1ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.6ms\n",
            "Speed: 2.0ms preprocess, 19.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.8ms\n",
            "Speed: 4.5ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.5ms\n",
            "Speed: 2.4ms preprocess, 17.5ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 2.5ms preprocess, 22.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.8ms\n",
            "Speed: 2.5ms preprocess, 20.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.6ms\n",
            "Speed: 2.4ms preprocess, 20.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.5ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.2ms\n",
            "Speed: 3.3ms preprocess, 18.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 4.1ms preprocess, 21.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.3ms\n",
            "Speed: 3.8ms preprocess, 19.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.5ms\n",
            "Speed: 2.2ms preprocess, 23.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 3.1ms preprocess, 17.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.1ms\n",
            "Speed: 4.2ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.1ms\n",
            "Speed: 2.3ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.7ms\n",
            "Speed: 2.5ms preprocess, 19.7ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.3ms preprocess, 17.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.6ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.6ms\n",
            "Speed: 3.8ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.5ms preprocess, 17.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.3ms\n",
            "Speed: 2.2ms preprocess, 17.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.1ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.8ms\n",
            "Speed: 2.1ms preprocess, 21.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.0ms preprocess, 21.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 25.7ms\n",
            "Speed: 3.0ms preprocess, 25.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.0ms\n",
            "Speed: 3.0ms preprocess, 19.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 2.2ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.7ms\n",
            "Speed: 3.4ms preprocess, 18.7ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.2ms\n",
            "Speed: 4.8ms preprocess, 18.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.3ms\n",
            "Speed: 3.7ms preprocess, 22.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.8ms\n",
            "Speed: 3.1ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.5ms\n",
            "Speed: 2.7ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 25.2ms\n",
            "Speed: 5.0ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.4ms\n",
            "Speed: 2.1ms preprocess, 22.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.6ms\n",
            "Speed: 2.1ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 3.5ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 27.5ms\n",
            "Speed: 1.9ms preprocess, 27.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.2ms\n",
            "Speed: 2.5ms preprocess, 19.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.2ms\n",
            "Speed: 2.3ms preprocess, 22.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 20.6ms\n",
            "Speed: 2.4ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 20.7ms\n",
            "Speed: 2.4ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.6ms\n",
            "Speed: 2.5ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 25.7ms\n",
            "Speed: 2.3ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.9ms preprocess, 17.6ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.4ms\n",
            "Speed: 2.7ms preprocess, 18.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.3ms\n",
            "Speed: 2.1ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.5ms\n",
            "Speed: 2.5ms preprocess, 21.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.3ms\n",
            "Speed: 3.9ms preprocess, 18.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.1ms\n",
            "Speed: 2.0ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.1ms\n",
            "Speed: 3.1ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.3ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 3.1ms preprocess, 17.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 4.6ms preprocess, 21.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 2.1ms preprocess, 22.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.0ms\n",
            "Speed: 2.8ms preprocess, 18.0ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.0ms\n",
            "Speed: 3.8ms preprocess, 18.0ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.9ms\n",
            "Speed: 3.6ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 2.0ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.0ms\n",
            "Speed: 2.2ms preprocess, 21.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.5ms\n",
            "Speed: 3.5ms preprocess, 21.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 19.6ms\n",
            "Speed: 3.0ms preprocess, 19.6ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.8ms\n",
            "Speed: 3.7ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.9ms\n",
            "Speed: 4.1ms preprocess, 24.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 2.2ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.8ms\n",
            "Speed: 2.5ms preprocess, 21.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.8ms\n",
            "Speed: 3.7ms preprocess, 18.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 19.0ms\n",
            "Speed: 5.4ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.2ms\n",
            "Speed: 2.0ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.8ms preprocess, 21.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.2ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 2.3ms preprocess, 21.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 3.3ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 18.1ms\n",
            "Speed: 4.9ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.6ms\n",
            "Speed: 2.9ms preprocess, 22.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.1ms preprocess, 17.7ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.7ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.2ms\n",
            "Speed: 2.3ms preprocess, 22.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 19.2ms\n",
            "Speed: 2.6ms preprocess, 19.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 24.7ms\n",
            "Speed: 4.5ms preprocess, 24.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.5ms\n",
            "Speed: 2.4ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.1ms\n",
            "Speed: 2.7ms preprocess, 22.1ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 3.0ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 19.8ms\n",
            "Speed: 4.0ms preprocess, 19.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 4.0ms preprocess, 22.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 19.4ms\n",
            "Speed: 3.6ms preprocess, 19.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.0ms\n",
            "Speed: 2.9ms preprocess, 22.0ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 2.1ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.5ms preprocess, 21.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.9ms preprocess, 21.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.3ms\n",
            "Speed: 1.9ms preprocess, 23.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.4ms\n",
            "Speed: 2.2ms preprocess, 24.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.0ms\n",
            "Speed: 3.0ms preprocess, 21.0ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.9ms\n",
            "Speed: 2.3ms preprocess, 17.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.1ms preprocess, 17.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 4.2ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 3.7ms preprocess, 21.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.6ms\n",
            "Speed: 2.0ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.4ms\n",
            "Speed: 2.1ms preprocess, 17.4ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.0ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 20.8ms\n",
            "Speed: 2.6ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 3.6ms preprocess, 21.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.8ms\n",
            "Speed: 2.0ms preprocess, 23.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 3.6ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 24.2ms\n",
            "Speed: 3.3ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 2.2ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.1ms preprocess, 21.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 3.7ms preprocess, 17.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 4.2ms preprocess, 17.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.7ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.9ms\n",
            "Speed: 2.2ms preprocess, 23.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 2.5ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 2.1ms preprocess, 17.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.8ms\n",
            "Speed: 2.5ms preprocess, 17.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 2.1ms preprocess, 22.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.1ms\n",
            "Speed: 2.4ms preprocess, 23.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.8ms\n",
            "Speed: 1.9ms preprocess, 18.8ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.6ms\n",
            "Speed: 2.0ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.2ms\n",
            "Speed: 2.2ms preprocess, 21.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 3.5ms preprocess, 21.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.1ms\n",
            "Speed: 2.2ms preprocess, 21.1ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.6ms\n",
            "Speed: 2.3ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 22.7ms\n",
            "Speed: 2.2ms preprocess, 22.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 2.6ms preprocess, 21.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 2.1ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 20.7ms\n",
            "Speed: 2.7ms preprocess, 20.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.5ms\n",
            "Speed: 3.5ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 20.5ms\n",
            "Speed: 3.9ms preprocess, 20.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.5ms\n",
            "Speed: 2.2ms preprocess, 23.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.4ms\n",
            "Speed: 3.5ms preprocess, 21.4ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.5ms\n",
            "Speed: 2.9ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.6ms\n",
            "Speed: 3.3ms preprocess, 17.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.7ms\n",
            "Speed: 5.6ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.4ms\n",
            "Speed: 4.2ms preprocess, 23.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 26.4ms\n",
            "Speed: 2.7ms preprocess, 26.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.9ms\n",
            "Speed: 3.1ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 21.8ms\n",
            "Speed: 2.1ms preprocess, 21.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 18.7ms\n",
            "Speed: 3.0ms preprocess, 18.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 23.7ms\n",
            "Speed: 5.0ms preprocess, 23.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 25.0ms\n",
            "Speed: 3.5ms preprocess, 25.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 23.1ms\n",
            "Speed: 2.5ms preprocess, 23.1ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.8ms\n",
            "Speed: 2.9ms preprocess, 24.8ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.3ms\n",
            "Speed: 4.0ms preprocess, 24.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.6ms\n",
            "Speed: 2.8ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.3ms\n",
            "Speed: 3.9ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.6ms\n",
            "Speed: 3.0ms preprocess, 18.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.3ms\n",
            "Speed: 3.2ms preprocess, 24.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.4ms\n",
            "Speed: 2.7ms preprocess, 22.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.6ms\n",
            "Speed: 2.6ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.8ms\n",
            "Speed: 3.7ms preprocess, 17.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.9ms\n",
            "Speed: 5.2ms preprocess, 18.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.7ms\n",
            "Speed: 3.6ms preprocess, 18.7ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.0ms\n",
            "Speed: 3.7ms preprocess, 20.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.8ms\n",
            "Speed: 3.2ms preprocess, 17.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.4ms\n",
            "Speed: 4.3ms preprocess, 18.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.7ms\n",
            "Speed: 3.4ms preprocess, 23.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.1ms\n",
            "Speed: 3.0ms preprocess, 23.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.3ms\n",
            "Speed: 2.4ms preprocess, 20.3ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.7ms\n",
            "Speed: 2.4ms preprocess, 17.7ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.1ms\n",
            "Speed: 2.8ms preprocess, 22.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.7ms\n",
            "Speed: 2.5ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.2ms\n",
            "Speed: 3.9ms preprocess, 21.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.2ms\n",
            "Speed: 2.7ms preprocess, 20.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.6ms\n",
            "Speed: 2.8ms preprocess, 21.6ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 21.1ms\n",
            "Speed: 2.9ms preprocess, 21.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 17.2ms\n",
            "Speed: 3.2ms preprocess, 17.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 18.9ms\n",
            "Speed: 2.2ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 20.4ms\n",
            "Speed: 2.5ms preprocess, 20.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 21.9ms\n",
            "Speed: 2.2ms preprocess, 21.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.5ms\n",
            "Speed: 2.9ms preprocess, 22.5ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 21.1ms\n",
            "Speed: 2.9ms preprocess, 21.1ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 18.4ms\n",
            "Speed: 3.3ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 19.4ms\n",
            "Speed: 4.4ms preprocess, 19.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 23.6ms\n",
            "Speed: 2.1ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.7ms\n",
            "Speed: 2.2ms preprocess, 23.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 20.2ms\n",
            "Speed: 2.5ms preprocess, 20.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 17.2ms\n",
            "Speed: 2.6ms preprocess, 17.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.9ms\n",
            "Speed: 2.8ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 3.6ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 24.6ms\n",
            "Speed: 3.5ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.5ms\n",
            "Speed: 2.2ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.2ms\n",
            "Speed: 4.0ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.6ms\n",
            "Speed: 3.7ms preprocess, 23.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.4ms\n",
            "Speed: 3.0ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.3ms\n",
            "Speed: 1.9ms preprocess, 21.3ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.2ms\n",
            "Speed: 2.7ms preprocess, 17.2ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 4.0ms preprocess, 22.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.3ms\n",
            "Speed: 2.8ms preprocess, 22.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 27.1ms\n",
            "Speed: 2.1ms preprocess, 27.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 mask_weared_incorrect, 17.5ms\n",
            "Speed: 2.2ms preprocess, 17.5ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 mask_weared_incorrects, 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 22.2ms\n",
            "Speed: 2.0ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 21.3ms\n",
            "Speed: 3.5ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 23.9ms\n",
            "Speed: 2.1ms preprocess, 23.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 24.2ms\n",
            "Speed: 3.4ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.2ms\n",
            "Speed: 3.5ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.9ms\n",
            "Speed: 3.9ms preprocess, 20.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.6ms\n",
            "Speed: 3.4ms preprocess, 21.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.0ms\n",
            "Speed: 4.4ms preprocess, 19.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.7ms\n",
            "Speed: 1.9ms preprocess, 21.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 24.7ms\n",
            "Speed: 3.8ms preprocess, 24.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 22.7ms\n",
            "Speed: 3.0ms preprocess, 22.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 22.6ms\n",
            "Speed: 2.2ms preprocess, 22.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 23.7ms\n",
            "Speed: 4.2ms preprocess, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 21.5ms\n",
            "Speed: 3.3ms preprocess, 21.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 17.9ms\n",
            "Speed: 3.4ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.8ms\n",
            "Speed: 2.0ms preprocess, 21.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 (no detections), 21.9ms\n",
            "Speed: 4.0ms preprocess, 21.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 with_masks, 23.5ms\n",
            "Speed: 2.4ms preprocess, 23.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.0ms\n",
            "Speed: 2.6ms preprocess, 18.0ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.9ms\n",
            "Speed: 3.0ms preprocess, 21.9ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.5ms\n",
            "Speed: 2.7ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.7ms\n",
            "Speed: 3.7ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.5ms\n",
            "Speed: 3.1ms preprocess, 24.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.4ms\n",
            "Speed: 2.3ms preprocess, 24.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.0ms\n",
            "Speed: 4.4ms preprocess, 19.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.5ms\n",
            "Speed: 2.4ms preprocess, 22.5ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 26.5ms\n",
            "Speed: 2.3ms preprocess, 26.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.4ms\n",
            "Speed: 3.7ms preprocess, 18.4ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.0ms\n",
            "Speed: 3.3ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.5ms\n",
            "Speed: 2.1ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 19.5ms\n",
            "Speed: 3.3ms preprocess, 19.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 27.4ms\n",
            "Speed: 2.2ms preprocess, 27.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.4ms\n",
            "Speed: 2.1ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.4ms\n",
            "Speed: 2.8ms preprocess, 21.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.1ms\n",
            "Speed: 4.2ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.0ms\n",
            "Speed: 4.5ms preprocess, 21.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 24.6ms\n",
            "Speed: 2.4ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 26.8ms\n",
            "Speed: 3.5ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.2ms\n",
            "Speed: 3.3ms preprocess, 22.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 25.5ms\n",
            "Speed: 3.6ms preprocess, 25.5ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 18.4ms\n",
            "Speed: 3.7ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.4ms\n",
            "Speed: 2.2ms preprocess, 23.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 20.2ms\n",
            "Speed: 4.4ms preprocess, 20.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.2ms\n",
            "Speed: 2.3ms preprocess, 22.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 21.3ms\n",
            "Speed: 2.4ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 27.8ms\n",
            "Speed: 3.0ms preprocess, 27.8ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 22.2ms\n",
            "Speed: 3.2ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 23.8ms\n",
            "Speed: 2.2ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 mask_weared_incorrect, 23.0ms\n",
            "Speed: 2.5ms preprocess, 23.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 without_masks, 1 mask_weared_incorrect, 24.3ms\n",
            "Speed: 2.8ms preprocess, 24.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 1 mask_weared_incorrect, 26.3ms\n",
            "Speed: 2.3ms preprocess, 26.3ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.7ms\n",
            "Speed: 2.2ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.3ms\n",
            "Speed: 3.2ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.2ms\n",
            "Speed: 3.1ms preprocess, 18.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.4ms\n",
            "Speed: 2.4ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 23.8ms\n",
            "Speed: 2.2ms preprocess, 23.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 17.6ms\n",
            "Speed: 2.3ms preprocess, 17.6ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.3ms\n",
            "Speed: 2.5ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.1ms\n",
            "Speed: 2.6ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.6ms\n",
            "Speed: 3.0ms preprocess, 17.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 19.4ms\n",
            "Speed: 3.4ms preprocess, 19.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.9ms\n",
            "Speed: 3.0ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 19.8ms\n",
            "Speed: 4.9ms preprocess, 19.8ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.6ms\n",
            "Speed: 2.3ms preprocess, 21.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.3ms\n",
            "Speed: 2.1ms preprocess, 21.3ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.6ms\n",
            "Speed: 2.4ms preprocess, 20.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.9ms\n",
            "Speed: 3.3ms preprocess, 21.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.4ms\n",
            "Speed: 3.7ms preprocess, 22.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.6ms\n",
            "Speed: 2.3ms preprocess, 22.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 27.1ms\n",
            "Speed: 2.1ms preprocess, 27.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.3ms\n",
            "Speed: 3.7ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 21.9ms\n",
            "Speed: 3.5ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 26.8ms\n",
            "Speed: 2.5ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 27.6ms\n",
            "Speed: 4.8ms preprocess, 27.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 19.4ms\n",
            "Speed: 5.7ms preprocess, 19.4ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.2ms\n",
            "Speed: 4.7ms preprocess, 25.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.2ms\n",
            "Speed: 2.5ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.7ms\n",
            "Speed: 5.5ms preprocess, 22.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 3.3ms preprocess, 22.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 27.2ms\n",
            "Speed: 2.9ms preprocess, 27.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.1ms\n",
            "Speed: 2.3ms preprocess, 21.1ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.3ms\n",
            "Speed: 3.9ms preprocess, 22.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.8ms\n",
            "Speed: 2.0ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 20.3ms\n",
            "Speed: 3.5ms preprocess, 20.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 17.5ms\n",
            "Speed: 2.0ms preprocess, 17.5ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 with_mask, 1 without_mask, 27.4ms\n",
            "Speed: 2.4ms preprocess, 27.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.7ms\n",
            "Speed: 2.5ms preprocess, 21.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 18.0ms\n",
            "Speed: 3.4ms preprocess, 18.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 22.0ms\n",
            "Speed: 3.6ms preprocess, 22.0ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.8ms\n",
            "Speed: 2.5ms preprocess, 23.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 27.1ms\n",
            "Speed: 2.1ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 24.6ms\n",
            "Speed: 3.9ms preprocess, 24.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 21.2ms\n",
            "Speed: 2.5ms preprocess, 21.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 23.1ms\n",
            "Speed: 2.4ms preprocess, 23.1ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 without_mask, 25.7ms\n",
            "Speed: 3.9ms preprocess, 25.7ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        }
      ],
      "source": [
        "# é¢„æµ‹è¾“å‡º\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------ å…¨å±€é…ç½® ------------\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"runs/detect/train/weights/best.pt\"\n",
        "model = YOLO(MODEL_PATH)\n",
        "# INPUT_PATH = \"dataset/output/test/\"  # è¾“å…¥è·¯å¾„,å¯ä»¥ä¸ºå›¾ç‰‡,è§†é¢‘,æ–‡ä»¶å¤¹,æ‘„åƒå¤´ç¼–å·\n",
        "# INPUT_PATH = \"dataset/output/video/test.mp4\"  # è¾“å…¥è·¯å¾„,å¯ä»¥ä¸ºå›¾ç‰‡,è§†é¢‘,æ–‡ä»¶å¤¹,æ‘„åƒå¤´ç¼–å·\n",
        "INPUT_PATH=0\n",
        "\n",
        "SAVE = True  # æ˜¯å¦ä¿å­˜é¢„æµ‹ç»“æžœ\n",
        "OUTPUT_PATH = \"predict/\"  # é¢„æµ‹ç»“æžœä¿å­˜è·¯å¾„\n",
        "\n",
        "# ------------ å·¥å…·å‡½æ•° ------------\n",
        "def draw_boxes_pil(image, results):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    try=\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "    except=\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
        "\n",
        "        text_bbox = font.getbbox(label)\n",
        "        text_w, text_h = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
        "        draw.rectangle([x1, y1 - text_h, x1 + text_w, y1], fill=\"red\")\n",
        "        draw.text((x1, y1 - text_h), label, fill=\"white\", font=font)\n",
        "\n",
        "    return image\n",
        "\n",
        "def save_image(image, save_path, origin_path=None):\n",
        "    if os.path.isdir(save_path)=\n",
        "        filename = os.path.basename(origin_path)\n",
        "        save_path = os.path.join(save_path, filename)\n",
        "    else:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    image.save(save_path)\n",
        "    print(f\"âœ… å·²ä¿å­˜å›¾ç‰‡= {save_path}\")\n",
        "\n",
        "# ------------ å•å›¾é¢„æµ‹ ------------\n",
        "def predict_image(image_path, save=False, save_path=None):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    results = model.predict(image_path, imgsz=640, device=DEVICE)\n",
        "    image = draw_boxes_pil(image, results)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"é¢„æµ‹ç»“æžœ\")\n",
        "    plt.show()\n",
        "\n",
        "    if save and save_path=\n",
        "        save_image(image, save_path, origin_path=image_path)\n",
        "\n",
        "# ------------ è§†é¢‘é¢„æµ‹ ------------\n",
        "def predict_video(video_path, save=False, save_path=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened()=\n",
        "        print(\"âŒ è§†é¢‘æ–‡ä»¶æ— æ³•æ‰“å¼€\")\n",
        "        return\n",
        "\n",
        "    if save=\n",
        "        if os.path.isdir(save_path):\n",
        "            filename = os.path.basename(video_path)\n",
        "            save_path = os.path.join(save_path, f\"{os.path.splitext(filename)[0]}.mp4\")\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        fps, w, h = cap.get(5), int(cap.get(3)), int(cap.get(4))\n",
        "        out = cv2.VideoWriter(save_path, fourcc, fps, (w, h))\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.predict(frame, imgsz=640, device=DEVICE)\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            cls_id = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"é¢„æµ‹ä¸­ - æŒ‰ Q é€€å‡º\", frame)\n",
        "        if save:\n",
        "            out.write(frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    if save=\n",
        "        out.release()\n",
        "        print(f\"âœ… å·²ä¿å­˜è§†é¢‘= {save_path}\")\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ------------ æ–‡ä»¶å¤¹æ‰¹é‡å›¾ç‰‡ ------------\n",
        "def predict_folder(folder_path, save=False, output_dir=None):\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")):\n",
        "                img_path = os.path.join(root, file)\n",
        "                image = Image.open(img_path).convert(\"RGB\")\n",
        "                results = model.predict(img_path, imgsz=640, device=DEVICE)\n",
        "                image = draw_boxes_pil(image, results)\n",
        "\n",
        "                if save and output_dir=\n",
        "                    rel_path = os.path.relpath(img_path, folder_path)\n",
        "                    save_path = os.path.join(output_dir, rel_path)\n",
        "                    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "                    image.save(save_path)\n",
        "\n",
        "    if save:\n",
        "        print(f\"âœ… æ–‡ä»¶å¤¹é¢„æµ‹å®Œæˆï¼Œç»“æžœå·²ä¿å­˜è‡³= {output_dir}\")\n",
        "\n",
        "# ------------ æ‘„åƒå¤´å®žæ—¶é¢„æµ‹ ------------\n",
        "def predict_camera(index=0):\n",
        "    cap = cv2.VideoCapture(index)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {index}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.predict(frame, imgsz=640, device=DEVICE)\n",
        "        for box in results[0].boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            cls_id = int(box.cls)\n",
        "            conf = float(box.conf)\n",
        "            label = f\"{model.names[cls_id]} {conf=.2f}\"\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"æ‘„åƒå¤´é¢„æµ‹ - æŒ‰ Q é€€å‡º\", frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ------------ æ€»å…¥å£å‡½æ•° ------------\n",
        "def run_predict(path, save=False, save_path=None):\n",
        "    if isinstance(path, int):\n",
        "        predict_camera(index=path)\n",
        "    elif os.path.isfile(path):\n",
        "        ext = os.path.splitext(path)[1].lower()\n",
        "        if ext in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]=\n",
        "            predict_image(path, save, save_path)\n",
        "        elif ext in [\".mp4\", \".avi\", \".mov\", \".mkv\"]:\n",
        "            predict_video(path, save, save_path)\n",
        "    elif os.path.isdir(path):\n",
        "        predict_folder(path, save, save_path)\n",
        "    else:\n",
        "        print(\"âŒ æ— æ•ˆè·¯å¾„ï¼Œè¯·ç¡®è®¤è¾“å…¥æ­£ç¡®çš„å›¾ç‰‡/è§†é¢‘/æ–‡ä»¶å¤¹/æ‘„åƒå¤´ç¼–å·\")\n",
        "\n",
        "# ------------ ç¤ºä¾‹è°ƒç”¨ ------------\n",
        "run_predict(INPUT_PATH, SAVE, OUTPUT_PATH)      # é¢„æµ‹è¾“å‡º"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}